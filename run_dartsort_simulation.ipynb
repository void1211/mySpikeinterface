{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "32f24427",
      "metadata": {},
      "outputs": [],
      "source": [
        "# CUDAメモリ断片化対策（OOM対策・torchより前に設定）\n",
        "import os\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pprint\n",
        "import json\n",
        "import torch\n",
        "import gc\n",
        "import traceback\n",
        "import time\n",
        "from scipy.io import savemat\n",
        "from datetime import datetime\n",
        "from myTools.output_converter import convert_to_matlab_files\n",
        "from kilosort.run_kilosort import load_sorting\n",
        "from probeinterface.io import write_probeinterface\n",
        "\n",
        "from myTools.read_spikeglx import get_exp_path, read_spikeglx_meta\n",
        "from myTools.set_gain_and_offset import set_gain_and_offset\n",
        "from myTools.init_run import get_recording, get_probe, get_probe_sorted, set_probe_info, get_stimtime\n",
        "\n",
        "import spikeinterface.full as si\n",
        "# import spikeinterface.extractors as se\n",
        "import spikeinterface.preprocessing as spre\n",
        "import spikeinterface.sorters as ss\n",
        "# import spikeinterface.postprocessing as spost\n",
        "# import spikeinterface.qualitymetrics as sqm\n",
        "# import spikeinterface.comparison as sc\n",
        "import spikeinterface.exporters as sexp\n",
        "# import spikeinterface.curation as scur\n",
        "# import spikeinterface.widgets as sw\n",
        "\n",
        "from kilosort.plots import plot_drift_amount, plot_drift_scatter, plot_diagnostics, plot_spike_positions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9b16f26b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### Select experiment ###\n",
        "dir_info = {\n",
        "    \"root_dir\": r\"C:\\Users\\tanaka-users\\NeuronData\",\n",
        "    \"name\": \"ge6w2\",\n",
        "    \"ep\": \"005\",\n",
        "    \"run\": \"002\",\n",
        "    \"ng\": \"0\",\n",
        "    \"nt\": \"0\",\n",
        "}\n",
        "\n",
        "dict_path = get_exp_path(dir_info)\n",
        "\n",
        "### Setting sorters ###\n",
        "do_preprocess = False\n",
        "do_runsort = False\n",
        "do_export_phy = False\n",
        "sorter = \"dartsort\"\n",
        "\n",
        "# DARTsortのデフォルトパラメータを取得\n",
        "sort_params = ss.get_default_sorter_params(\"dartsort\")\n",
        "\n",
        "name_thisparam = \"setting8\"\n",
        "\n",
        "# GMM refinement のメモリ削減（core_features は全スパイク分確保されるため core_radius が重要）\n",
        "sort_params[\"gmm_max_spikes\"] = 250_000   # 300k で OOM なら 150k にさらに下げる\n",
        "# sort_params[\"gmm_val_proportion\"] = 0.1   # デフォルト: 0.25 → 0.1\n",
        "# TVI/processor の Coo_invsqrt 等は近傍サイズに比例するため、OOM 時は core_radius を下げる\n",
        "sort_params[\"core_radius\"] = 10           # デフォルト: \"extract\" → 12（processor update PCA の GPU OOM 対策）\n",
        "# sort_params[\"n_refinement_iters\"] = 1    # 1にするとsplitをスキップしGPU OOMを回避\n",
        "# sort_params[\"later_steps\"] = \"merge\"     # splitを行わずmergeのみ（メモリ削減）\n",
        "\n",
        "# name_thisparam = \"param2\"\n",
        "# sort_params[\"gmm_max_spikes\"] = 500_000 # デフォルト: 2000000 → 50000に大幅削減（refine用）\n",
        "# sort_params[\"gmm_val_proportion\"] = 0.1  # デフォルト: 0.25 → 0.1に削減（メモリ削減）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0f401bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Fetch meta and bin files ###\n",
        "meta_ap = read_spikeglx_meta(dict_path[\"ap\"][\"meta\"])\n",
        "meta_lf = read_spikeglx_meta(dict_path[\"lf\"][\"meta\"])\n",
        "meta_obx = read_spikeglx_meta(dict_path[\"obx\"][\"meta\"])\n",
        "\n",
        "recording, sync_recording = get_recording(meta_ap, dict_path[\"ap\"][\"bin\"])\n",
        "probe = get_probe(meta_ap)\n",
        "probe = set_probe_info(probe, meta_ap)\n",
        "recording = recording.set_probe(probe)\n",
        "probe = get_probe_sorted(recording, probe)\n",
        "recording = recording.set_probe(probe)\n",
        "recording = set_gain_and_offset(meta_ap, recording)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5054e6f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip preprocessing.\n"
          ]
        }
      ],
      "source": [
        "### Preprocess recording ###\n",
        "if do_preprocess:\n",
        "\n",
        "    print(\"\\n\" + \"=\"*20 + \" parameter \" + \"=\"*20)\n",
        "    print(f\"\\n{'='*5} {sorter} {'='*5}\")\n",
        "    pprint.pprint(sort_params)\n",
        "\n",
        "    params_file = dict_path[\"exp\"] / sorter / name_thisparam / \"params.txt\"\n",
        "    params_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(str(params_file), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(sort_params, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(\"=\"*5, sorter, \"=\"*5)\n",
        "    folder = dict_path[\"exp\"] / sorter / name_thisparam\n",
        "    pp_rec_folder = folder / \"pp_rec\"\n",
        "\n",
        "    # DARTsort用前処理（NaN/Inf を避けるためmean common referenceを使用）\n",
        "    print(f\"  バンドパスフィルタ適用中...\")\n",
        "    recording_f = spre.bandpass_filter(recording, freq_min=300, freq_max=3000)\n",
        "    \n",
        "    # medianではなくmean common referenceを使用（NaN生成を回避）\n",
        "    # medianは同じ値が続く場合や極端な値がある場合にNaNを生成する可能性がある\n",
        "    print(f\"  Common reference適用中... (mean)\")\n",
        "    try:\n",
        "        recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"mean\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Common reference (mean) でエラー: {e}\")\n",
        "        print(f\"  フォールバック: median common referenceを使用\")\n",
        "        recording_cmr = spre.common_reference(recording_f, reference=\"global\", operator=\"median\")\n",
        "    \n",
        "    # 前処理recordingを保存（NaN/Infチェックは後で実行）\n",
        "    recording_preprocessed = recording_cmr.save(format=\"binary\", folder=pp_rec_folder, overwrite=True)\n",
        "else:\n",
        "    print(\"skip preprocessing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9aa7a033",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip sorting.\n"
          ]
        }
      ],
      "source": [
        "### Run sorting ###\n",
        "if do_runsort:\n",
        "    print(f\"{'='*5} {sorter} {'='*5}\")\n",
        "    print(f\"  {sorter}実行開始: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        \n",
        "        sorter_output_dir = dict_path[\"exp\"] / sorter / name_thisparam / \"sorting\"\n",
        "        sorting = ss.run_sorter(\n",
        "            sorter_name=sorter,\n",
        "            folder=sorter_output_dir, \n",
        "            remove_existing_folder=True, \n",
        "            recording=recording,\n",
        "            verbose=True,\n",
        "            **sort_params\n",
        "            )\n",
        "            \n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"  {sorter}実行完了: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (経過時間: {elapsed_time/60:.1f}分)\")\n",
        "\n",
        "        print(f\"  Analyzer作成開始: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        analyzer = si.create_sorting_analyzer(sorting=sorting, recording=recording, format='binary_folder', folder=dict_path[\"exp\"] / sorter / name_thisparam / \"analyzer\", overwrite=True)\n",
        "        print(analyzer)\n",
        "        print(\"===== Sorting done =====\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while running {sorter}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            print(f\"  GPUメモリクリア完了 - 割り当て済み: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"skip sorting.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e67f2c63",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skip export to phy.\n"
          ]
        }
      ],
      "source": [
        "### export to phy ###\n",
        "if do_export_phy:\n",
        "    analyzer = si.load_sorting_analyzer(folder= dict_path[\"exp\"] / sorter / name_thisparam / \"analyzer\")\n",
        "    analyzer.compute(['random_spikes', 'waveforms', 'templates'])\n",
        "    # PC特徴の計算が時間かかってそうなので、Falseにしておく\n",
        "    sexp.export_to_phy(sorting_analyzer=analyzer, output_folder=dict_path[\"exp\"] / sorter / name_thisparam / \"phy\", remove_if_exists=True,\n",
        "                            compute_pc_features=False)\n",
        "else:\n",
        "    print(\"skip export to phy.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d5619d21",
      "metadata": {},
      "outputs": [],
      "source": [
        "### convert to matlab files ###\n",
        "convert_to_matlab_files(phy_dir=dict_path[\"exp\"] / sorter / name_thisparam / \"phy\", recording=recording)\n",
        "\n",
        "### export to probe.json ###\n",
        "write_probeinterface(dict_path[\"exp\"] / sorter / name_thisparam / \"probe.json\", probe_or_probegroup=probe)\n",
        "\n",
        "stim_times_rise, stim_times_fall, fs_obx = get_stimtime(meta_obx, dict_path[\"obx\"][\"bin\"])\n",
        "savemat(dict_path[\"exp\"] / sorter / name_thisparam / \"stim_times.mat\", {'stim_times_rise': stim_times_rise, 'stim_times_fall': stim_times_fall, 'fs': fs_obx})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b504a8cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from dartsort.util.data_util import DARTsortSorting\n",
        "\n",
        "# # .npzファイルからロード（HDF5も自動的に読み込まれる）\n",
        "# sorting = DARTsortSorting.load(\n",
        "#     r\"C:\\Users\\tanaka-users\\NeuronData\\ge6w2\\ge6w2_ep005_002\\DARTsort\\setting3\\sorting\\sorter_output\\dartsort_sorting.npz\"\n",
        "# )\n",
        "\n",
        "# # データにアクセス\n",
        "# print(f\"スパイク数: {sorting.n_spikes}\")\n",
        "# print(f\"ユニット数: {sorting.n_units}\")\n",
        "# print(f\"サンプリング周波数: {sorting.sampling_frequency}\")\n",
        "\n",
        "# # 基本データ\n",
        "# times_samples = sorting.times_samples\n",
        "# channels = sorting.channels\n",
        "# labels = sorting.labels\n",
        "\n",
        "# # 追加特徴量（HDF5から読み込まれたもの）\n",
        "# if sorting.extra_features:\n",
        "#     print(f\"利用可能な特徴量: {list(sorting.extra_features.keys())}\")\n",
        "#     print(sorting.geom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4c101036",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ### export to matlab files for ks4 ###\n",
        "# conv_ks4_mat(res_dir=dict_path[\"exp\"] / sorter / name_thisparam / \"sorting\" / \"sorter_output\", recording=recording)\n",
        "\n",
        "# ### export to probe.json ###\n",
        "# write_probeinterface(dict_path[\"exp\"] / sorter / name_thisparam / \"probe.json\", probe_or_probegroup=probe)\n",
        "\n",
        "# ### plot drift amount, scatter, diagnostics, spike positions ###\n",
        "# ks_dir = dict_path[\"exp\"] / sorter / name_thisparam / \"sorting\" / \"sorter_output\"\n",
        "# ops, st, clu, similar_templates, \\\n",
        "#     is_ref, est_contam_rate, kept_spikes, \\\n",
        "#         tF, Wall, full_st, full_clu, full_amp = \\\n",
        "#             load_sorting(ks_dir, device=\"cuda\", load_extra_vars=True)\n",
        "\n",
        "# plot_drift_amount(ops, ks_dir)\n",
        "# plot_drift_scatter(full_st, ks_dir)\n",
        "# plot_diagnostics(Wall, full_clu, ops, ks_dir)\n",
        "# plot_spike_positions(clu, is_ref, ks_dir)\n",
        "\n",
        "\n",
        "# stim_times_rise, stim_times_fall, fs_obx = get_stimtime(meta_obx, dict_path[\"obx\"][\"bin\"])\n",
        "# savemat(dict_path[\"exp\"] / sorter / name_thisparam / \"stim_times.mat\", {'stim_times_rise': stim_times_rise, 'stim_times_fall': stim_times_fall, 'fs': fs_obx})\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
